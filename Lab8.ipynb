{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae790492",
   "metadata": {},
   "source": [
    "Текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e66c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Предобработка текста — это первый и один из наиболее важных этапов в обработке естественного языка (NLP) с использованием нейронных сетей. Этот процесс включает в себя серию операций, предназначенных для преобразования исходного текста в формат, который может быть эффективно обработан нейронными сетями.'\n",
    "text2 = 'Шла Саша по шоссе и сосала сушку.'\n",
    "text3 = 'Санкт-Петербург — один из крупнейших промышленных центров России, лидер по производству машиностроительной продукции, создаёт 11% от общего объёма продукции машиностроения по стране.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc80a38",
   "metadata": {},
   "source": [
    "Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c12979d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aleka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import punkt\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "681fe53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BlanklineTokenizer',\n",
       " 'LegalitySyllableTokenizer',\n",
       " 'LineTokenizer',\n",
       " 'MWETokenizer',\n",
       " 'NLTKWordTokenizer',\n",
       " 'PunktSentenceTokenizer',\n",
       " 'RegexpTokenizer',\n",
       " 'ReppTokenizer',\n",
       " 'SExprTokenizer',\n",
       " 'SpaceTokenizer',\n",
       " 'StanfordSegmenter',\n",
       " 'SyllableTokenizer',\n",
       " 'TabTokenizer',\n",
       " 'TextTilingTokenizer',\n",
       " 'ToktokTokenizer',\n",
       " 'TreebankWordDetokenizer',\n",
       " 'TreebankWordTokenizer',\n",
       " 'TweetTokenizer']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "dir(tokenize)[:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7436a5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Предобработка',\n",
       " 'текста',\n",
       " '—',\n",
       " 'это',\n",
       " 'первый',\n",
       " 'и',\n",
       " 'один',\n",
       " 'из',\n",
       " 'наиболее',\n",
       " 'важных',\n",
       " 'этапов',\n",
       " 'в',\n",
       " 'обработке',\n",
       " 'естественного',\n",
       " 'языка',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'с',\n",
       " 'использованием',\n",
       " 'нейронных',\n",
       " 'сетей',\n",
       " '.',\n",
       " 'Этот',\n",
       " 'процесс',\n",
       " 'включает',\n",
       " 'в',\n",
       " 'себя',\n",
       " 'серию',\n",
       " 'операций',\n",
       " ',',\n",
       " 'предназначенных',\n",
       " 'для',\n",
       " 'преобразования',\n",
       " 'исходного',\n",
       " 'текста',\n",
       " 'в',\n",
       " 'формат',\n",
       " ',',\n",
       " 'который',\n",
       " 'может',\n",
       " 'быть',\n",
       " 'эффективно',\n",
       " 'обработан',\n",
       " 'нейронными',\n",
       " 'сетями',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_tk_1 = nltk.WordPunctTokenizer()\n",
    "nltk_tk_1.tokenize(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b6e3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Предобработка текста — это первый и один из наиболее важных этапов в обработке естественного языка (NLP) с использованием нейронных сетей.',\n",
       " 'Этот процесс включает в себя серию операций, предназначенных для преобразования исходного текста в формат, который может быть эффективно обработан нейронными сетями.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Токенизация по предложениям\n",
    "nltk_tk_sents = nltk.tokenize.sent_tokenize(text1)\n",
    "print(len(nltk_tk_sents))\n",
    "nltk_tk_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8bd2050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import tokenize, sentenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf30f7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0, 13, 'Предобработка'),\n",
       " Substring(14, 20, 'текста'),\n",
       " Substring(21, 22, '—'),\n",
       " Substring(23, 26, 'это'),\n",
       " Substring(27, 33, 'первый'),\n",
       " Substring(34, 35, 'и'),\n",
       " Substring(36, 40, 'один'),\n",
       " Substring(41, 43, 'из'),\n",
       " Substring(44, 52, 'наиболее'),\n",
       " Substring(53, 59, 'важных'),\n",
       " Substring(60, 66, 'этапов'),\n",
       " Substring(67, 68, 'в'),\n",
       " Substring(69, 78, 'обработке'),\n",
       " Substring(79, 92, 'естественного'),\n",
       " Substring(93, 98, 'языка'),\n",
       " Substring(99, 100, '('),\n",
       " Substring(100, 103, 'NLP'),\n",
       " Substring(103, 104, ')'),\n",
       " Substring(105, 106, 'с'),\n",
       " Substring(107, 121, 'использованием'),\n",
       " Substring(122, 131, 'нейронных'),\n",
       " Substring(132, 137, 'сетей'),\n",
       " Substring(137, 138, '.'),\n",
       " Substring(139, 143, 'Этот'),\n",
       " Substring(144, 151, 'процесс'),\n",
       " Substring(152, 160, 'включает'),\n",
       " Substring(161, 162, 'в'),\n",
       " Substring(163, 167, 'себя'),\n",
       " Substring(168, 173, 'серию'),\n",
       " Substring(174, 182, 'операций'),\n",
       " Substring(182, 183, ','),\n",
       " Substring(184, 199, 'предназначенных'),\n",
       " Substring(200, 203, 'для'),\n",
       " Substring(204, 218, 'преобразования'),\n",
       " Substring(219, 228, 'исходного'),\n",
       " Substring(229, 235, 'текста'),\n",
       " Substring(236, 237, 'в'),\n",
       " Substring(238, 244, 'формат'),\n",
       " Substring(244, 245, ','),\n",
       " Substring(246, 253, 'который'),\n",
       " Substring(254, 259, 'может'),\n",
       " Substring(260, 264, 'быть'),\n",
       " Substring(265, 275, 'эффективно'),\n",
       " Substring(276, 285, 'обработан'),\n",
       " Substring(286, 296, 'нейронными'),\n",
       " Substring(297, 303, 'сетями'),\n",
       " Substring(303, 304, '.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tok_text1 = list(tokenize(text1))\n",
    "n_tok_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fc3f38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Предобработка',\n",
       " 'текста',\n",
       " '—',\n",
       " 'это',\n",
       " 'первый',\n",
       " 'и',\n",
       " 'один',\n",
       " 'из',\n",
       " 'наиболее',\n",
       " 'важных',\n",
       " 'этапов',\n",
       " 'в',\n",
       " 'обработке',\n",
       " 'естественного',\n",
       " 'языка',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'с',\n",
       " 'использованием',\n",
       " 'нейронных',\n",
       " 'сетей',\n",
       " '.',\n",
       " 'Этот',\n",
       " 'процесс',\n",
       " 'включает',\n",
       " 'в',\n",
       " 'себя',\n",
       " 'серию',\n",
       " 'операций',\n",
       " ',',\n",
       " 'предназначенных',\n",
       " 'для',\n",
       " 'преобразования',\n",
       " 'исходного',\n",
       " 'текста',\n",
       " 'в',\n",
       " 'формат',\n",
       " ',',\n",
       " 'который',\n",
       " 'может',\n",
       " 'быть',\n",
       " 'эффективно',\n",
       " 'обработан',\n",
       " 'нейронными',\n",
       " 'сетями',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.text for _ in n_tok_text1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f2d5dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0,\n",
       "           138,\n",
       "           'Предобработка текста — это первый и один из наиболее важных этапов в обработке естественного языка (NLP) с использованием нейронных сетей.'),\n",
       " Substring(139,\n",
       "           304,\n",
       "           'Этот процесс включает в себя серию операций, предназначенных для преобразования исходного текста в формат, который может быть эффективно обработан нейронными сетями.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sen_text1 = list(sentenize(text1))\n",
    "n_sen_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e989aaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Предобработка текста — это первый и один из наиболее важных этапов в обработке естественного языка (NLP) с использованием нейронных сетей.',\n",
       "  'Этот процесс включает в себя серию операций, предназначенных для преобразования исходного текста в формат, который может быть эффективно обработан нейронными сетями.'],\n",
       " 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.text for _ in n_sen_text1], len([_.text for _ in n_sen_text1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008a5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Этот вариант токенизации нужен для последующей обработки\n",
    "def n_sentenize(text):\n",
    "    n_sen_chunk = []\n",
    "    for sent in sentenize(text):\n",
    "        tokens = [_.text for _ in tokenize(sent.text)]\n",
    "        n_sen_chunk.append(tokens)\n",
    "    return n_sen_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c4c3c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Предобработка',\n",
       "  'текста',\n",
       "  '—',\n",
       "  'это',\n",
       "  'первый',\n",
       "  'и',\n",
       "  'один',\n",
       "  'из',\n",
       "  'наиболее',\n",
       "  'важных',\n",
       "  'этапов',\n",
       "  'в',\n",
       "  'обработке',\n",
       "  'естественного',\n",
       "  'языка',\n",
       "  '(',\n",
       "  'NLP',\n",
       "  ')',\n",
       "  'с',\n",
       "  'использованием',\n",
       "  'нейронных',\n",
       "  'сетей',\n",
       "  '.'],\n",
       " ['Этот',\n",
       "  'процесс',\n",
       "  'включает',\n",
       "  'в',\n",
       "  'себя',\n",
       "  'серию',\n",
       "  'операций',\n",
       "  ',',\n",
       "  'предназначенных',\n",
       "  'для',\n",
       "  'преобразования',\n",
       "  'исходного',\n",
       "  'текста',\n",
       "  'в',\n",
       "  'формат',\n",
       "  ',',\n",
       "  'который',\n",
       "  'может',\n",
       "  'быть',\n",
       "  'эффективно',\n",
       "  'обработан',\n",
       "  'нейронными',\n",
       "  'сетями',\n",
       "  '.']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sen_chunk_1 = n_sentenize(text1)\n",
    "n_sen_chunk_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fb39958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Шла', 'Саша', 'по', 'шоссе', 'и', 'сосала', 'сушку', '.']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sen_chunk_2 = n_sentenize(text2)\n",
    "n_sen_chunk_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea11deb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Санкт-Петербург',\n",
       "  '—',\n",
       "  'один',\n",
       "  'из',\n",
       "  'крупнейших',\n",
       "  'промышленных',\n",
       "  'центров',\n",
       "  'России',\n",
       "  ',',\n",
       "  'лидер',\n",
       "  'по',\n",
       "  'производству',\n",
       "  'машиностроительной',\n",
       "  'продукции',\n",
       "  ',',\n",
       "  'создаёт',\n",
       "  '11',\n",
       "  '%',\n",
       "  'от',\n",
       "  'общего',\n",
       "  'объёма',\n",
       "  'продукции',\n",
       "  'машиностроения',\n",
       "  'по',\n",
       "  'стране',\n",
       "  '.']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sen_chunk_3 = n_sentenize(text3)\n",
    "n_sen_chunk_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa18935d",
   "metadata": {},
   "source": [
    "Частеречная разметка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f37512ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "from slovnet import Morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2e746fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Файл необходимо скачать по ссылке https://github.com/natasha/navec#downloads\n",
    "navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "974e5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Файл необходимо скачать по ссылке https://github.com/natasha/slovnet#downloads\n",
    "n_morph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47e8738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_res = n_morph.navec(navec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4e6533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pos(markup):\n",
    "    for token in markup.tokens:\n",
    "        print('{} - {}'.format(token.text, token.tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b68a090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предобработка - ADJ|Case=Gen|Degree=Pos|Gender=Masc|Number=Sing\n",
      "текста - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      "— - PUNCT\n",
      "это - PART\n",
      "первый - ADJ|Case=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
      "и - CCONJ\n",
      "один - NUM|Case=Nom|Gender=Masc|Number=Sing\n",
      "из - ADP\n",
      "наиболее - ADV|Degree=Pos\n",
      "важных - ADJ|Case=Gen|Degree=Pos|Number=Plur\n",
      "этапов - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Plur\n",
      "в - ADP\n",
      "обработке - NOUN|Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\n",
      "естественного - ADJ|Case=Gen|Degree=Pos|Gender=Masc|Number=Sing\n",
      "языка - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      "( - PUNCT\n",
      "NLP - PROPN|Foreign=Yes\n",
      ") - PUNCT\n",
      "с - ADP\n",
      "использованием - NOUN|Animacy=Inan|Case=Ins|Gender=Neut|Number=Sing\n",
      "нейронных - ADJ|Case=Gen|Degree=Pos|Number=Plur\n",
      "сетей - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur\n",
      ". - PUNCT\n",
      "Этот - DET|Case=Nom|Gender=Masc|Number=Sing\n",
      "процесс - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
      "включает - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "в - ADP\n",
      "себя - PRON|Case=Acc\n",
      "серию - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
      "операций - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur\n",
      ", - PUNCT\n",
      "предназначенных - VERB|Aspect=Perf|Case=Gen|Number=Plur|Tense=Past|VerbForm=Part|Voice=Pass\n",
      "для - ADP\n",
      "преобразования - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
      "исходного - ADJ|Case=Gen|Degree=Pos|Gender=Masc|Number=Sing\n",
      "текста - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      "в - ADP\n",
      "формат - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
      ", - PUNCT\n",
      "который - PRON|Case=Nom|Gender=Masc|Number=Sing\n",
      "может - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "быть - AUX|Aspect=Imp|VerbForm=Inf|Voice=Act\n",
      "эффективно - ADV|Degree=Pos\n",
      "обработан - VERB|Aspect=Perf|Gender=Masc|Number=Sing|Tense=Past|Variant=Short|VerbForm=Part|Voice=Pass\n",
      "нейронными - ADJ|Case=Ins|Degree=Pos|Number=Plur\n",
      "сетями - NOUN|Animacy=Inan|Case=Ins|Gender=Fem|Number=Plur\n",
      ". - PUNCT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_text1_markup = list(_ for _ in n_morph.map(n_sen_chunk_1))\n",
    "[print_pos(x) for x in n_text1_markup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d3efa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шла - VERB|Aspect=Imp|Gender=Fem|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
      "Саша - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
      "по - ADP\n",
      "шоссе - NOUN|Animacy=Inan|Case=Dat|Gender=Neut|Number=Sing\n",
      "и - CCONJ\n",
      "сосала - ADJ|Case=Acc|Degree=Pos|Gender=Fem|Number=Sing\n",
      "сушку - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
      ". - PUNCT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_text2_markup = list(n_morph.map(n_sen_chunk_2))\n",
    "[print_pos(x) for x in n_text2_markup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8e16468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Санкт-Петербург - PROPN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
      "— - PUNCT\n",
      "один - NUM|Case=Nom|Gender=Masc|Number=Sing\n",
      "из - ADP\n",
      "крупнейших - ADJ|Case=Gen|Degree=Sup|Number=Plur\n",
      "промышленных - ADJ|Case=Gen|Degree=Pos|Number=Plur\n",
      "центров - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Plur\n",
      "России - PROPN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      ", - PUNCT\n",
      "лидер - NOUN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
      "по - ADP\n",
      "производству - NOUN|Animacy=Inan|Case=Dat|Gender=Neut|Number=Sing\n",
      "машиностроительной - ADJ|Case=Gen|Degree=Pos|Gender=Fem|Number=Sing\n",
      "продукции - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      ", - PUNCT\n",
      "создаёт - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "11 - NUM\n",
      "% - SYM\n",
      "от - ADP\n",
      "общего - ADJ|Case=Gen|Degree=Pos|Gender=Masc|Number=Sing\n",
      "объёма - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      "продукции - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "машиностроения - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
      "по - ADP\n",
      "стране - NOUN|Animacy=Inan|Case=Dat|Gender=Fem|Number=Sing\n",
      ". - PUNCT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_text3_markup = list(n_morph.map(n_sen_chunk_3))\n",
    "[print_pos(x) for x in n_text3_markup]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd006ead",
   "metadata": {},
   "source": [
    "Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d454f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import Doc, Segmenter, NewsEmbedding, NewsMorphTagger, MorphVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a61aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_lemmatize(text):\n",
    "    emb = NewsEmbedding()\n",
    "    morph_tagger = NewsMorphTagger(emb)\n",
    "    segmenter = Segmenter()\n",
    "    morph_vocab = MorphVocab()\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "227d9543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Предобработка': 'предобработка',\n",
       " 'текста': 'текст',\n",
       " '—': '—',\n",
       " 'это': 'это',\n",
       " 'первый': 'первый',\n",
       " 'и': 'и',\n",
       " 'один': 'один',\n",
       " 'из': 'из',\n",
       " 'наиболее': 'наиболее',\n",
       " 'важных': 'важный',\n",
       " 'этапов': 'этап',\n",
       " 'в': 'в',\n",
       " 'обработке': 'обработка',\n",
       " 'естественного': 'естественный',\n",
       " 'языка': 'язык',\n",
       " '(': '(',\n",
       " 'NLP': 'nlp',\n",
       " ')': ')',\n",
       " 'с': 'с',\n",
       " 'использованием': 'использование',\n",
       " 'нейронных': 'нейронный',\n",
       " 'сетей': 'сеть',\n",
       " '.': '.',\n",
       " 'Этот': 'этот',\n",
       " 'процесс': 'процесс',\n",
       " 'включает': 'включать',\n",
       " 'себя': 'себя',\n",
       " 'серию': 'серия',\n",
       " 'операций': 'операция',\n",
       " ',': ',',\n",
       " 'предназначенных': 'предназначить',\n",
       " 'для': 'для',\n",
       " 'преобразования': 'преобразование',\n",
       " 'исходного': 'исходный',\n",
       " 'формат': 'формат',\n",
       " 'который': 'который',\n",
       " 'может': 'мочь',\n",
       " 'быть': 'быть',\n",
       " 'эффективно': 'эффективно',\n",
       " 'обработан': 'обработать',\n",
       " 'нейронными': 'нейронный',\n",
       " 'сетями': 'сеть'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_doc1 = n_lemmatize(text1)\n",
    "{_.text: _.lemma for _ in n_doc1.tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b9eeed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Шла': 'идти',\n",
       " 'Саша': 'саша',\n",
       " 'по': 'по',\n",
       " 'шоссе': 'шоссе',\n",
       " 'и': 'и',\n",
       " 'сосала': 'сосать',\n",
       " 'сушку': 'сушка',\n",
       " '.': '.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_doc2 = n_lemmatize(text2)\n",
    "{_.text: _.lemma for _ in n_doc2.tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46237b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Санкт-Петербург': 'санкт-петербург',\n",
       " '—': '—',\n",
       " 'один': 'один',\n",
       " 'из': 'из',\n",
       " 'крупнейших': 'крупный',\n",
       " 'промышленных': 'промышленный',\n",
       " 'центров': 'центр',\n",
       " 'России': 'россия',\n",
       " ',': ',',\n",
       " 'лидер': 'лидер',\n",
       " 'по': 'по',\n",
       " 'производству': 'производство',\n",
       " 'машиностроительной': 'машиностроительный',\n",
       " 'продукции': 'продукция',\n",
       " 'создаёт': 'создавать',\n",
       " '11': '11',\n",
       " '%': '%',\n",
       " 'от': 'от',\n",
       " 'общего': 'общий',\n",
       " 'объёма': 'объем',\n",
       " 'машиностроения': 'машиностроение',\n",
       " 'стране': 'страна',\n",
       " '.': '.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_doc3 = n_lemmatize(text3)\n",
    "{_.text: _.lemma for _ in n_doc3.tokens}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f762a98f",
   "metadata": {},
   "source": [
    "Выделение (распознавание) именованных сущностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2a495e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slovnet import NER\n",
    "from ipymarkup import show_span_ascii_markup as show_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e28cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = NER.load('slovnet_ner_news_v1.tar')\n",
    "ner_res = ner.navec(navec)\n",
    "markup_ner3 = ner(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff3bec8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpanMarkup(\n",
       "    text='Санкт-Петербург — один из крупнейших промышленных центров России, лидер по производству машиностроительной продукции, создаёт 11% от общего объёма продукции машиностроения по стране.',\n",
       "    spans=[Span(\n",
       "         start=0,\n",
       "         stop=15,\n",
       "         type='LOC'\n",
       "     ),\n",
       "     Span(\n",
       "         start=58,\n",
       "         stop=64,\n",
       "         type='LOC'\n",
       "     )]\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup_ner3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fab806c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Санкт-Петербург — один из крупнейших промышленных центров России, \n",
      "LOC────────────                                           LOC───  \n",
      "лидер по производству машиностроительной продукции, создаёт 11% от \n",
      "общего объёма продукции машиностроения по стране.\n"
     ]
    }
   ],
   "source": [
    "show_markup(markup_ner3.text, markup_ner3.spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c8f8b4",
   "metadata": {},
   "source": [
    "Разбор предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc478f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import NewsSyntaxParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5422b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = NewsEmbedding()\n",
    "syntax_parser = NewsSyntaxParser(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd1c2fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ┌► Предобработка  amod\n",
      "          ┌─└─ текста         \n",
      "          └──► —              punct\n",
      "    ┌────────► это            expl\n",
      "    │ ┌──►┌─── первый         parataxis\n",
      "    │ │   │ ┌► и              cc\n",
      "    │ │   └►└─ один           conj\n",
      "    │ │ ┌────► из             case\n",
      "    │ │ │   ┌► наиболее       advmod\n",
      "    │ │ │ ┌►└─ важных         amod\n",
      "┌───└─└─└─└─── этапов         nmod\n",
      "│     │ │   ┌► в              case\n",
      "│   ┌─└►└───└─ обработке      nmod\n",
      "│   │       ┌► естественного  amod\n",
      "│ ┌─└──────►└─ языка          nmod\n",
      "│ │         ┌► (              punct\n",
      "│ └──────►┌─└─ NLP            appos\n",
      "│         └──► )              punct\n",
      "│           ┌► с              case\n",
      "└────────►┌─└─ использованием nmod\n",
      "          │ ┌► нейронных      amod\n",
      "          └►└─ сетей          nmod\n",
      "               .              \n"
     ]
    }
   ],
   "source": [
    "n_doc1.parse_syntax(syntax_parser)\n",
    "n_doc1.sents[0].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f23d7e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ┌► Этот            det\n",
      "        ┌►└─ процесс         nsubj\n",
      "┌─┌─┌─┌─└─── включает        \n",
      "│ │ │ │   ┌► в               case\n",
      "│ │ │ └──►└─ себя            obl\n",
      "│ │ └────►┌─ серию           obj\n",
      "│ │     ┌─└► операций        nmod\n",
      "│ │     │ ┌► ,               punct\n",
      "│ │   ┌─└►└─ предназначенных acl\n",
      "│ │   │   ┌► для             case\n",
      "│ │ ┌─└──►└─ преобразования  obl\n",
      "│ │ │     ┌► исходного       amod\n",
      "│ │ └────►└─ текста          nmod\n",
      "│ │       ┌► в               case\n",
      "│ └──►┌───└─ формат          obl\n",
      "│     │ ┌──► ,               punct\n",
      "│     │ │ ┌► который         nsubj:pass\n",
      "│   ┌─└►└─└─ может           acl:relcl\n",
      "│   │   ┌──► быть            aux:pass\n",
      "│   │   │ ┌► эффективно      advmod\n",
      "│   └►┌─└─└─ обработан       xcomp\n",
      "│     │   ┌► нейронными      amod\n",
      "│     └──►└─ сетями          obl\n",
      "└──────────► .               punct\n"
     ]
    }
   ],
   "source": [
    "n_doc1.parse_syntax(syntax_parser)\n",
    "n_doc1.sents[1].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8aa6efa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Шла    \n",
      "       Саша   \n",
      "    ┌► по     case\n",
      "    └─ шоссе  \n",
      "┌────► и      cc\n",
      "│ ┌─┌► сосала amod\n",
      "└─└►└─ сушку  obj\n",
      "       .      \n"
     ]
    }
   ],
   "source": [
    "n_doc2.parse_syntax(syntax_parser)\n",
    "n_doc2.sents[0].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "305023ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌──► Санкт-Петербург    nsubj\n",
      "        │ ┌► —                  punct\n",
      "┌─┌─┌───└─└─ один               \n",
      "│ │ │ ┌────► из                 case\n",
      "│ │ │ │ ┌──► крупнейших         amod\n",
      "│ │ │ │ │ ┌► промышленных       amod\n",
      "│ │ └►└─└─└─ центров            nmod\n",
      "│ │     └──► России             nmod\n",
      "│ │       ┌► ,                  punct\n",
      "│ └────►┌─└─ лидер              conj\n",
      "│       │ ┌► по                 case\n",
      "│     ┌─└►└─ производству       nmod\n",
      "│     │   ┌► машиностроительной amod\n",
      "│     └──►└─ продукции          nmod\n",
      "│         ┌► ,                  punct\n",
      "│     ┌─┌─└─ создаёт            \n",
      "│     │ │ ┌► 11                 nummod\n",
      "│     │ └►└─ %                  obj\n",
      "│     │ ┌──► от                 case\n",
      "│     │ │ ┌► общего             amod\n",
      "│     └►└─└─ объёма             obl\n",
      "│     ┌─└►┌─ продукции          nmod\n",
      "│     │   └► машиностроения     nmod\n",
      "│     │   ┌► по                 case\n",
      "│     └──►└─ стране             nmod\n",
      "└──────────► .                  punct\n"
     ]
    }
   ],
   "source": [
    "n_doc3.parse_syntax(syntax_parser)\n",
    "n_doc3.sents[0].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050d1f93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
